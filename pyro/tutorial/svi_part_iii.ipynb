{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVI パート3： ELBO 勾配の推定法\n",
    "\n",
    "## はじめに\n",
    "\n",
    "\n",
    "* SVI で興味のあるパラメータは2種類\n",
    "    * 確率モデルのパラメータ $\\theta$\n",
    "    * 変分分布（ガイド）の変分パラメータ $\\phi$\n",
    "* 究極の目的である、対数エビデンス $\\log p(x;\\theta)$ 最大化の為に、$\\theta$ と $\\phi$ に関して ELBO を最大化する\n",
    "    * ELBO の最大化は $\\{ \\theta, \\phi \\}$ で張られるパラメータ空間での勾配降下によって実行する\n",
    "    * なので、ELBO の勾配 $\\nabla_{\\theta,\\phi} \\mathrm{ELBO}$ が欲しい\n",
    "* 一般の確率モデルと変分分布に対してELBOの勾配を求めるにはどうすればいい？\n",
    "    * ここでは簡単のため $\\theta$ と $\\phi$ の区別をなくし、$\\phi$ に統一して議論を進める\n",
    "    * つまり次を求めることを考える\n",
    "$$\n",
    "\\nabla _ { \\phi } \\mathbb { E } _ { q _ { \\phi } ( \\mathbf { z } ) } \\left[ f _ { \\phi } ( \\mathbf { z } ) \\right]\n",
    "$$\n",
    "\n",
    "### 簡単なケース：再パラメータ化可能な確率変数\n",
    "\n",
    "$$\n",
    "\\mathbb { E } _ { q _ { \\phi } ( \\mathbf { z } ) } \\left[ f _ { \\phi } ( \\mathbf { z } ) \\right] = \\mathbb { E } _ { q ( \\epsilon ) } \\left[ f _ { \\phi } \\left( g _ { \\phi } ( \\epsilon ) \\right) \\right]\n",
    "$$\n",
    "\n",
    "* VAE とかで使われてるテクニック\n",
    "* 微分可能な関数 $g(\\epsilon, \\phi)$ で $z$ を求めることができれば簡単に微分できる\n",
    "    * ただし $\\epsilon$ は $\\phi$ に関係ない分布 $q(\\epsilon)$ に従う\n",
    "* $\\nabla_\\phi$ を取ると、期待値計算の中にはいるのでモンテカルロ方による推定ができる\n",
    "\n",
    "### やっかいなケース： 最パラメータ化できない確率変数\n",
    "\n",
    "（一般の）ELBOに対する勾配の定義 \n",
    "$$\n",
    "\\nabla _ { \\phi } \\mathbb { E } _ { q _ { \\phi } ( \\mathbf { z } ) } \\left[ f _ { \\phi } ( \\mathbf { z } ) \\right] = \\nabla _ { \\phi } \\int q _ { \\phi } ( \\mathbf { z } ) f _ { \\phi } ( \\mathbf { z } ) d \\mathbf { z } \n",
    "$$\n",
    "に、勾配のチェインルールを使うと\n",
    "$$\n",
    "\\int \\left\\{ \\left( \\nabla _ { \\phi } q _ { \\phi } ( \\mathbf { z } ) \\right) f _ { \\phi } ( \\mathbf { z } ) + q _ { \\phi } ( \\mathbf { z } ) \\left( \\nabla _ { \\phi } f _ { \\phi } ( \\mathbf { z } ) \\right) \\right\\} d \\mathbf { z } \n",
    "$$\n",
    "となる。\n",
    "\n",
    "ここで、積分の中で $q(z)$ をまとめることを考える（なぜなら期待値として書けるから）。勾配に対して一般に成り立つ式\n",
    "$$\n",
    "\\nabla _ { \\phi } q _ { \\phi } ( \\mathbf { z } ) = q _ { \\phi } ( \\mathbf { z } ) \\nabla _ { \\phi } \\log q _ { \\phi } ( \\mathbf { z } )\n",
    "$$\n",
    "を使用すれば、結局\n",
    "$$\n",
    "\\mathbb { E } _ { q _ { \\phi } ( \\mathbf { z } ) } \\left[ \\left( \\nabla _ { \\phi } \\log q _ { \\phi } ( \\mathbf { z } ) \\right) f _ { \\phi } ( \\mathbf { z } ) + \\nabla _ { \\phi } f _ { \\phi } ( \\mathbf { z } ) \\right]\n",
    "$$\n",
    "を得る。\n",
    "\n",
    "* これは REINFORCE 推定量、スコア関数推定量、尤度比推定量として知られる推定量\n",
    "* $z \\sim q(z;\\phi)$ をサンプリングするモンテカルロ法によって近似計算可能\n",
    "* 実装ではこの中身を目的関数としてやる\n",
    "    * 結局 ELBO の微分をすれば、結局中身の微分（の期待値）になるから\n",
    "    * こういう目的関数を surrogate objective function という\n",
    "\n",
    "## ELBO 勾配推定量の分散が大きい問題\n",
    "\n",
    "* 一般的なモデルと変分分布に対する ELBO 勾配の近似計算方法を確認したが、大抵の場合この近似は高い分散を持つ\n",
    "    * REINFORCE「ELBO勾配の近似できた！」⇒ 全然違う…\n",
    "    * （ちなみにREINFORCE は不偏推定量なのでこれを100回とか繰り返すと安定する）\n",
    "* なので、分散が小さい推定量を得る戦略を考えなければならない\n",
    "    * 戦略1：コスト関数 $f(\\cdot)$ の構造を利用する方法\n",
    "    * 戦略2：前回の推定値を利用する方法\n",
    "    \n",
    "### 戦略1：依存構造を使った分散削減\n",
    "\n",
    "* 上の推定量の出し方は一般の $f$ に対する議論だったけど、私達が興味があるのは特殊な $f$、つまり ELBO\n",
    "    * ELBO の依存構造に注目するのがこの戦略\n",
    "* Rao-Blackwellの定理とよばれる定理を使えば、追加情報（i.e. 十分統計量）を使っtえ不偏推定量の分散を減らせるらしい\n",
    "    * モンテカルロ計算などで用いられている\n",
    "    * 詳細は他の資料を参照のこと\n",
    "* Rao-Blackwell を使うには、`SVI` のインスタンス化の際に `TraceGraph_ELBO` を渡すだけ\n",
    "    * 計算量が増加するので、むやみに使うもんでもない\n",
    "    * パラメータ化ができない潜在変数が存在するモデルに対してだけ使えばよくで、大体のモデルでは `Trace_ELBO` で十分\n",
    "* 使う時の注意としては、`plate` を使用しないと意味がないということ\n",
    "    * モデルの構造（条件付き独立性）を記述するには `plate` を使うしかない\n",
    "\n",
    "### 戦略2：ベースライン法\n",
    "\n",
    "* 2つめの分散低減戦略は baseline と呼ばれる手法\n",
    "* 期待値が 0 の（ELBO 勾配推定量の普遍性を変えないような）項を追加することを考える\n",
    "    * 戦略1では、期待値が 0 で分散増加に寄与する項を取り除く事を考えたけど、その反対\n",
    "\n",
    "目的関数\n",
    "$$\n",
    "\\log q _ { \\phi } \\left( \\mathbf { z } _ { i } \\right) \\overline { f _ { \\phi } ( \\mathbf { z } ) }\n",
    "$$\n",
    "を\n",
    "$$\n",
    "\\log q _ { \\phi } \\left( \\mathbf { z } _ { i } \\right) \\left( \\overline { f _ { \\phi } ( \\mathbf { z } ) } - b \\right)\n",
    "$$\n",
    "に変更する。\n",
    "\n",
    "* これの勾配の期待値は、元の目的関数の勾配期待値と同じだけど、分散が違う\n",
    "* 美味い具合に $b$ を選ぶことができれば、嬉しい\n",
    "    * $b$ をベースライン (baseline) という\n",
    "\n",
    "#### Pyro でのベースライン\n",
    "\n",
    "* Pyro ではいろんなベースラインを使う方法が提供されている\n",
    "* ベースラインは任意のパラメータ化不可能な確率変数に付与することが出来るので、確率変数の定義 `pyro.sample` の際に与える API になっている\n",
    "* 具体的には `baseline` 引数で指定する\n",
    "\n",
    "#### 減衰平均ベースライン\n",
    "\n",
    "```py\n",
    "z = pyro.sample(\"z\", dist.Bernoulli(...),\n",
    "                infer=dict(baseline={'use_decaying_avg_baseline': True,\n",
    "                                     'baseline_beta': 0.95}))\n",
    "```\n",
    "\n",
    "* 一番シンプルなのは、$\\overline{f(z;\\phi)}$ の移動指数平均を取る方法\n",
    "\n",
    "#### ニューラルベースライン\n",
    "\n",
    "* ベースラインをニューラルネットを用いて計算する手法\n",
    "    * 入力次元：観測データの数\n",
    "    * 出力次元：潜在変数の数\n",
    "* 詳細は [SVI Part III: ELBO Gradient Estimators — Pyro Tutorials 0.3.0 documentation](http://pyro.ai/examples/svi_part_iii.html#Neural-Baselines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import torch\n",
    "import torch.distributions.constraints as constraints\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "# Pyro also has a reparameterized Beta distribution so we import\n",
    "# the non-reparameterized version to make our point\n",
    "from pyro.distributions.testing.fakes import NonreparameterizedBeta\n",
    "import pyro.optim as optim\n",
    "from pyro.infer import SVI, TraceGraph_ELBO\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps = 10000\n",
    "\n",
    "def param_abs_error(name, target):\n",
    "    return torch.sum(torch.abs(target - pyro.param(name))).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BernoulliBetaExample(object):\n",
    "    def __init__(self, max_steps):\n",
    "        self.max_steps = max_steps\n",
    "        # モデルの超パラメータ（興味はない）\n",
    "        self.alpha0 = 10.0\n",
    "        self.beta0 = 10.0\n",
    "        # データ\n",
    "        self.data = torch.zeros(10)\n",
    "        self.data[0:6] = torch.ones(6)\n",
    "        self.n_data = self.data.size(0)\n",
    "        # 解析的に求まる事後分布のパラメータ\n",
    "        self.alpha_n = self.data.sum() + self.alpha0\n",
    "        self.beta_n = - self.data.sum() + torch.tensor(self.beta0 + self.n_data)\n",
    "        # 変分パラメータの初期値\n",
    "        self.alpha_q_0 = 15.0\n",
    "        self.beta_q_0 = 15.0\n",
    "        \n",
    "    def model(self, use_decaying_avg_baseline):\n",
    "        # 確率変数（潜在）の定義\n",
    "        f = pyro.sample(\"latent_fairness\", dist.Beta(self.alpha0, self.beta0))\n",
    "        # プレート表現\n",
    "        with pyro.plate(\"data_plate\"):\n",
    "            # 確率変数（観測）の定義\n",
    "            pyro.sample(\"obs\", dist.Bernoulli(f), obs=self.data)\n",
    "     \n",
    "    def guide(self, use_decaying_avg_baseline):\n",
    "        # 変分パラメータの定義\n",
    "        alpha_q = pyro.param(\"alpha_q\", torch.tensor(self.alpha_q_0),\n",
    "                            constraint=constraints.positive)\n",
    "        beta_q = pyro.param(\"beta_q\", torch.tensor(self.beta_q_0),\n",
    "                            constraint=constraints.positive)\n",
    "        # ベースラインの定義\n",
    "        baseline_dict = {\n",
    "            \"use_decaying_avg_baseline\": use_decaying_avg_baseline,\n",
    "            \"baseline_beta\": 0.90\n",
    "        }\n",
    "        \n",
    "        # モデルの潜在変数は、ガイドですべて定義する必要がある\n",
    "        # 今回は fairness だけを定義すればよく、変分パラメータに基づくベータ分布で定義した\n",
    "        pyro.sample(\"latent_fairness\",\n",
    "                    NonreparameterizedBeta(alpha_q, beta_q),\n",
    "                    infer=dict(baseline=baseline_dict))\n",
    "        \n",
    "    def do_inference(self, use_decaying_avg_baseline, tolerance=0.1):\n",
    "        # パラメータ（モデルパラメータと変分パラメータ）を一旦空にする\n",
    "        pyro.clear_param_store()\n",
    "        # オプティマイザのセットアップ\n",
    "        optimizer = optim.Adam({\"lr\": .0005, \"betas\": (0.93, 0.999)})\n",
    "        svi = SVI(self.model, self.guide, optimizer, loss=TraceGraph_ELBO())\n",
    "        print(\"Doing inference with use_decaying_avg_baseline = %s\" %\n",
    "             use_decaying_avg_baseline)\n",
    "        \n",
    "        for k in range(self.max_steps):\n",
    "            svi.step(use_decaying_avg_baseline)\n",
    "            if k % 100 == 0:\n",
    "                print('.', end='')\n",
    "                sys.stdout.flush()\n",
    "                \n",
    "            # 真のパラメータとの距離を計算する\n",
    "            alpha_error = param_abs_error(\"alpha_q\", self.alpha_n)\n",
    "            beta_error = param_abs_error(\"beta_q\", self.beta_n)\n",
    "            \n",
    "            # 収束したら終了する\n",
    "            if alpha_error < tolerance and beta_error < tolerance:\n",
    "                break\n",
    "                \n",
    "        _alpha_q = pyro.param('alpha_q').item()\n",
    "        _beta_q = pyro.param('beta_q').item()\n",
    "        print(\"\")\n",
    "        print(\"Did %d steps of inference.\" % (k + 1))\n",
    "        print(\"Final absolute errors for alpha and beta are:\")\n",
    "        print(f\"- alpha: {_alpha_q:.4f}, {alpha_error:.4f}\")\n",
    "        print(f\"- beta: {_beta_q:.4f}, {beta_error:.4f}\")\n",
    "        \n",
    "bbe = BernoulliBetaExample(max_steps=max_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing inference with use_decaying_avg_baseline = True\n",
      "........\n",
      "Did 794 steps of inference.\n",
      "Final absolute errors for alpha and beta are:\n",
      "- alpha: 15.9220, 0.0780\n",
      "- beta: 14.0998, 0.0998\n"
     ]
    }
   ],
   "source": [
    "bbe.do_inference(use_decaying_avg_baseline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing inference with use_decaying_avg_baseline = False\n",
      "...............................\n",
      "Did 3030 steps of inference.\n",
      "Final absolute errors for alpha and beta are:\n",
      "- alpha: 15.9013, 0.0987\n",
      "- beta: 13.9610, 0.0390\n"
     ]
    }
   ],
   "source": [
    "bbe.do_inference(use_decaying_avg_baseline=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
